{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Schema:\n",
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      "\n",
      "\n",
      "Orders Schema:\n",
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n",
      "\n",
      "Products Schema:\n",
      "root\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "\n",
      "Order Items Schema:\n",
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- product_id: long (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"EcommerceAnalysis\").getOrCreate()\n",
    "\n",
    "# Create Customers DataFrame\n",
    "customers_data = [\n",
    "    (1, \"Alice\", \"alice@example.com\", \"2022-01-15\"),\n",
    "    (2, \"Bob\", \"bob@example.com\", \"2022-03-10\"),\n",
    "    (3, \"Charlie\", \"charlie@example.com\", \"2022-05-20\"),\n",
    "    (4, \"David\", \"david@example.com\", \"2022-07-05\")\n",
    "]\n",
    "customers_df = spark.createDataFrame(customers_data, [\"customer_id\", \"name\", \"email\", \"join_date\"])\n",
    "\n",
    "# Create Orders DataFrame\n",
    "orders_data = [\n",
    "    (101, 1, \"2023-01-10\", 150.50),\n",
    "    (102, 2, \"2023-01-12\", 200.00),\n",
    "    (103, 1, \"2023-02-05\", 75.25),\n",
    "    (104, 3, \"2023-02-18\", 300.75),\n",
    "    (105, 4, \"2023-03-01\", 50.00),\n",
    "    (106, 2, \"2023-03-15\", 120.00)\n",
    "]\n",
    "orders_df = spark.createDataFrame(orders_data, [\"order_id\", \"customer_id\", \"order_date\", \"total_amount\"])\n",
    "\n",
    "# Create Products DataFrame\n",
    "products_data = [\n",
    "    (1001, \"Laptop\", 999.99, \"Electronics\"),\n",
    "    (1002, \"Smartphone\", 599.99, \"Electronics\"),\n",
    "    (1003, \"Headphones\", 99.99, \"Accessories\"),\n",
    "    (1004, \"Keyboard\", 49.99, \"Accessories\")\n",
    "]\n",
    "products_df = spark.createDataFrame(products_data, [\"product_id\", \"name\", \"price\", \"category\"])\n",
    "\n",
    "order_items_data = [\n",
    "    (101, 1001, 1, 999.99),  # order_id, product_id, quantity, price\n",
    "    (101, 1003, 1, 99.99),\n",
    "    (102, 1002, 1, 599.99),\n",
    "    (103, 1004, 2, 49.99),   # 2 keyboards\n",
    "    (104, 1001, 1, 999.99),\n",
    "    (104, 1002, 1, 599.99),\n",
    "    (105, 1003, 1, 99.99),\n",
    "    (106, 1004, 3, 49.99)    # 3 keyboards\n",
    "]\n",
    "\n",
    "order_items_df = spark.createDataFrame(order_items_data, schema=['order_id', 'product_id', 'quantity', 'price'])\n",
    "\n",
    "# Show schema for verification\n",
    "print(\"Customers Schema:\")\n",
    "customers_df.printSchema()\n",
    "print(\"\\nOrders Schema:\")\n",
    "orders_df.printSchema()\n",
    "print(\"\\nProducts Schema:\")\n",
    "products_df.printSchema()\n",
    "print(\"\\nOrder Items Schema:\")\n",
    "order_items_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------+----------+\n",
      "|customer_id|   name|              email| join_date|\n",
      "+-----------+-------+-------------------+----------+\n",
      "|          2|    Bob|    bob@example.com|2022-03-10|\n",
      "|          3|Charlie|charlie@example.com|2022-05-20|\n",
      "|          4|  David|  david@example.com|2022-07-05|\n",
      "+-----------+-------+-------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------------+\n",
      "|order_id|customer_id|order_date|total_amount|\n",
      "+--------+-----------+----------+------------+\n",
      "|     104|          3|2023-02-18|      300.75|\n",
      "|     102|          2|2023-01-12|       200.0|\n",
      "|     101|          1|2023-01-10|       150.5|\n",
      "|     106|          2|2023-03-15|       120.0|\n",
      "|     103|          1|2023-02-05|       75.25|\n",
      "|     105|          4|2023-03-01|        50.0|\n",
      "+--------+-----------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+\n",
      "|customer_id|   name|total_revenue|\n",
      "+-----------+-------+-------------+\n",
      "|          1|  Alice|       225.75|\n",
      "|          2|    Bob|        320.0|\n",
      "|          3|Charlie|       300.75|\n",
      "|          4|  David|         50.0|\n",
      "+-----------+-------+-------------+\n",
      "\n",
      "+--------+-------+-------------------+----------+------------+\n",
      "|order_id|   name|              email|order_date|total_amount|\n",
      "+--------+-------+-------------------+----------+------------+\n",
      "|     101|  Alice|  alice@example.com|2023-01-10|       150.5|\n",
      "|     103|  Alice|  alice@example.com|2023-02-05|       75.25|\n",
      "|     102|    Bob|    bob@example.com|2023-01-12|       200.0|\n",
      "|     106|    Bob|    bob@example.com|2023-03-15|       120.0|\n",
      "|     104|Charlie|charlie@example.com|2023-02-18|      300.75|\n",
      "|     105|  David|  david@example.com|2023-03-01|        50.0|\n",
      "+--------+-------+-------------------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----------------+-----------+\n",
      "|customer_id| name|avg_order_amount|order_count|\n",
      "+-----------+-----+----------------+-----------+\n",
      "|          1|Alice|         112.875|          2|\n",
      "|          2|  Bob|           160.0|          2|\n",
      "+-----------+-----+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtering: Find all customers who joined after '2022-03-01'\n",
    "filtered_customers = customers_df.filter(col(\"join_date\") > \"2022-03-01\")\n",
    "filtered_customers.show()\n",
    "\n",
    "# 2. Sorting: Sort orders by total_amount in descending order\n",
    "sorted_orders = orders_df.orderBy(col(\"total_amount\").desc())\n",
    "sorted_orders.show()\n",
    "\n",
    "# 3. Aggregation: Calculate the total revenue generated per customer (include customer name)\n",
    "customer_revenue = orders_df.join(customers_df, \"customer_id\") \\\n",
    "    .groupBy(\"customer_id\", \"name\") \\\n",
    "    .agg(sum(\"total_amount\").alias(\"total_revenue\"))\n",
    "customer_revenue.show()\n",
    "\n",
    "# 4. Joining: List all orders with customer details (name, email) and order details (order_date, total_amount)\n",
    "order_details = orders_df.join(customers_df, \"customer_id\") \\\n",
    "    .select(\"order_id\", \"name\", \"email\", \"order_date\", \"total_amount\")\n",
    "order_details.show()\n",
    "\n",
    "# 5. Advanced Aggregation: Find the average order amount for each customer, but only for those with at least 2 orders\n",
    "customer_avg = orders_df.groupBy(\"customer_id\") \\\n",
    "    .agg(\n",
    "        avg(\"total_amount\").alias(\"avg_order_amount\"),\n",
    "        count(\"order_id\").alias(\"order_count\")\n",
    "    ) \\\n",
    "    .filter(col(\"order_count\") >= 2) \\\n",
    "    .join(customers_df, \"customer_id\") \\\n",
    "    .select(\"customer_id\", \"name\", \"avg_order_amount\", \"order_count\")\n",
    "customer_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|month_cnt|\n",
      "+---------+\n",
      "|        3|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 6: Distinct Counts - Find how many unique months customers placed orders in\n",
    "# Expected Output: Single number representing count of distinct months (YYYY-MM format)\n",
    "# Hint: First extract month from order_date, then count distinct values\n",
    "\n",
    "# Your PySpark solution here\n",
    "# Start with orders_df, transform order_date to 'yyyy-MM' format, then count distinct months\n",
    "orders_df.select(\n",
    "        date_format(col('order_date'), 'yyyy-MM').alias('year-month')\n",
    "    ).agg(\n",
    "        countDistinct(col('year-month')).alias('month_cnt')\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|year-month|total_revenue|\n",
      "+----------+-------------+\n",
      "|   2023-02|        376.0|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 7: Time Analysis - Find the month with the highest total revenue\n",
    "# Expected Output: Single row with [month_year, total_revenue] for the top month\n",
    "# Hint: Combine date_format, groupBy, sum, and orderBy\n",
    "\n",
    "orders_df.select(\n",
    "    date_format(col('order_date'), 'yyyy-MM').alias('year-month'),\n",
    "    col('total_amount')\n",
    ").groupBy(col('year-month')) \\\n",
    ".agg(\n",
    "    sum(col('total_amount')).alias('total_revenue')\n",
    ").orderBy(col('total_revenue').desc()) \\\n",
    ".limit(1) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+--------------------+\n",
      "|customer_id| name|distinct_month_count|\n",
      "+-----------+-----+--------------------+\n",
      "|          1|Alice|                   2|\n",
      "|          2|  Bob|                   2|\n",
      "+-----------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 8: Customer Order Frequency - Find customers who placed orders in at least 2 distinct months\n",
    "# Expected Output: DataFrame with [customer_id, name, distinct_month_count]\n",
    "# Should include Alice (Jan+Feb) and Bob (Jan+Mar) from sample data\n",
    "\n",
    "orders_df.select(\n",
    "    date_format('order_date', 'yyyy-MM').alias('year-month'),\n",
    "    col('customer_id')\n",
    ").join(customers_df, on='customer_id', how='inner') \\\n",
    ".groupBy(col('customer_id'), col('name')) \\\n",
    ".agg(\n",
    "    countDistinct(col('year-month')).alias('distinct_month_count')\n",
    ") \\\n",
    ".filter(col('distinct_month_count') >= 2) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+\n",
      "|customer_id|   name|total_spend|\n",
      "+-----------+-------+-----------+\n",
      "|          1|  Alice|     225.75|\n",
      "|          2|    Bob|      320.0|\n",
      "|          3|Charlie|     300.75|\n",
      "+-----------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 9: Customer Spending Comparison - Find customers who spent more than the average customer spend\n",
    "# Expected Output: DataFrame with [customer_id, name, total_spend] where total_spend > overall_avg\n",
    "# Note: overall_avg = average of all customers' total spending\n",
    "\n",
    "customer_spend = orders_df.groupBy('customer_id') \\\n",
    "    .agg(sum(col('total_amount')).alias('total_spend'))\n",
    "\n",
    "avg_customer_spend = customer_spend.agg(avg(col('total_spend')).alias('avg_customer_spend'))\n",
    "\n",
    "above_avg_customers = customer_spend.join(customers_df, on='customer_id', how='inner') \\\n",
    "    .join(avg_customer_spend, how='cross') \\\n",
    "    .filter(col('total_spend') > col('avg_customer_spend')) \\\n",
    "    .select(col('customer_id'), col('name'), col('total_spend'))\n",
    "\n",
    "above_avg_customers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+----------+----------------+\n",
      "|customer_id|   name|order_id|order_date|max_order_amount|\n",
      "+-----------+-------+--------+----------+----------------+\n",
      "|          1|  Alice|     101|2023-01-10|           150.5|\n",
      "|          2|    Bob|     102|2023-01-12|           200.0|\n",
      "|          3|Charlie|     104|2023-02-18|          300.75|\n",
      "|          4|  David|     105|2023-03-01|            50.0|\n",
      "+-----------+-------+--------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 10: Window Functions - Find each customer's most expensive order\n",
    "# Expected Output: DataFrame with [customer_id, name, order_id, order_date, max_order_amount]\n",
    "# Should show one row per customer with their highest-value order\n",
    "\n",
    "ranked_orders = orders_df.withColumn('rank', rank().over(Window.partitionBy('customer_id').orderBy(col('total_amount').desc())))\n",
    "\n",
    "top_orders = ranked_orders.join(customers_df, 'customer_id') \\\n",
    "    .filter(col('rank') == 1) \\\n",
    "    .select(\n",
    "        col('customer_id'), \n",
    "        col('name'), \n",
    "        col('order_id'), \n",
    "        col('order_date'), \n",
    "        col('total_amount').alias('max_order_amount')\n",
    "    )\n",
    "\n",
    "top_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------------+\n",
      "|customer_id| name|days_between_orders|\n",
      "+-----------+-----+-------------------+\n",
      "|          1|Alice|                 26|\n",
      "|          2|  Bob|                 62|\n",
      "+-----------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 11: Time Between Orders - Calculate the days between each customer's first and most recent order\n",
    "# Expected Output: DataFrame with [customer_id, name, days_between_orders]\n",
    "# Should show the time span in days for each customer with >1 order\n",
    "\n",
    "time_between_orders = (\n",
    "    orders_df\n",
    "    .groupBy('customer_id')\n",
    "    .agg(\n",
    "        min('order_date').alias('first_order_date'),\n",
    "        max('order_date').alias('last_order_date'),\n",
    "        count('order_id').alias('order_count')\n",
    "    )\n",
    "    .filter(col('order_count') > 1)\n",
    "    .withColumn('days_between_orders', datediff(col('last_order_date'), col('first_order_date')))\n",
    "    .join(customers_df, 'customer_id')\n",
    "    .select('customer_id', 'name', 'days_between_orders')\n",
    ")\n",
    "\n",
    "time_between_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-----------------------+\n",
      "|customer_id| name|avg_days_between_orders|\n",
      "+-----------+-----+-----------------------+\n",
      "|          1|Alice|                   26.0|\n",
      "|          2|  Bob|                   62.0|\n",
      "+-----------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 12: Order Frequency - Calculate the average time between orders (in days) for each customer\n",
    "# Expected Output: DataFrame with [customer_id, name, avg_days_between_orders]\n",
    "# Should show the mean time between consecutive orders for customers with ≥2 orders\n",
    "\n",
    "avg_time_between_orders = (\n",
    "    orders_df\n",
    "    .withColumn('prev_order_date', lag('order_date').over(Window.partitionBy('customer_id').orderBy('order_date')))\n",
    "    .withColumn('days_between', datediff(col('order_date'), col('prev_order_date')))\n",
    "    .groupBy('customer_id')\n",
    "    .agg(\n",
    "        avg('days_between').alias('avg_days_between_orders'),\n",
    "        count('order_id').alias('order_count')\n",
    "    )\n",
    "    .filter(\n",
    "        (col('order_count') >= 2) &\n",
    "        (col('avg_days_between_orders').isNotNull())\n",
    "    )\n",
    "    .join(customers_df, 'customer_id')\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'name',\n",
    "        'avg_days_between_orders'\n",
    "    )\n",
    ")\n",
    "\n",
    "avg_time_between_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------------------+\n",
      "|total_amount|customer_count|example_customer_id|\n",
      "+------------+--------------+-------------------+\n",
      "|       150.5|             1|                  1|\n",
      "|       200.0|             1|                  2|\n",
      "|       75.25|             1|                  1|\n",
      "|      300.75|             1|                  3|\n",
      "|        50.0|             1|                  4|\n",
      "|       120.0|             1|                  2|\n",
      "+------------+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 14 (Revised): Customer Order Patterns - Find customers who frequently order the same total amount\n",
    "# Expected Output: DataFrame with [amount, customer_count, example_customer_id]\n",
    "# Shows which order amounts appear most frequently across customers\n",
    "\n",
    "customer_order_patterns = (\n",
    "    orders_df\n",
    "    .groupBy('total_amount')\n",
    "    .agg(\n",
    "        count('customer_id').alias('customer_count'),\n",
    "        min('customer_id').alias('example_customer_id')\n",
    "    )\n",
    ")\n",
    "\n",
    "customer_order_patterns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+------+\n",
      "|customer_id|   name|total_spend|  tier|\n",
      "+-----------+-------+-----------+------+\n",
      "|          1|  Alice|     225.75|Silver|\n",
      "|          2|    Bob|      320.0|  Gold|\n",
      "|          3|Charlie|     300.75|  Gold|\n",
      "|          4|  David|       50.0|Bronze|\n",
      "+-----------+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 15: Customer Segmentation - Classify customers into spending tiers\n",
    "# Expected Output: DataFrame with [customer_id, name, total_spend, tier]\n",
    "# Tiers: \n",
    "#   Platinum: > $500 total spend\n",
    "#   Gold: $300-$500\n",
    "#   Silver: $100-$300\n",
    "#   Bronze: < $100\n",
    "\n",
    "customer_segmentation = (\n",
    "    orders_df\n",
    "    .groupBy('customer_id')\n",
    "    .agg(\n",
    "        sum('total_amount').alias('total_spend')\n",
    "    )\n",
    "    .withColumn('tier', \n",
    "                when(col('total_spend') > 500, 'Platinum')\n",
    "                .when((col('total_spend') > 300) & (col('total_spend') <= 500), 'Gold')\n",
    "                .when((col('total_spend') > 100) & (col('total_spend') <= 300), 'Silver')\n",
    "                .otherwise('Bronze')\n",
    "    )\n",
    "    .join(customers_df, 'customer_id')\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'name',\n",
    "        'total_spend',\n",
    "        'tier'\n",
    "    )\n",
    ")\n",
    "\n",
    "customer_segmentation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+---------------+\n",
      "|customer_id|order_date|total_amount|rolling_avg_30d|\n",
      "+-----------+----------+------------+---------------+\n",
      "|          1|2023-01-10|       150.5|          150.5|\n",
      "|          1|2023-02-05|       75.25|        112.875|\n",
      "|          2|2023-01-12|       200.0|          200.0|\n",
      "|          2|2023-03-15|       120.0|          120.0|\n",
      "|          3|2023-02-18|      300.75|         300.75|\n",
      "|          4|2023-03-01|        50.0|           50.0|\n",
      "+-----------+----------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 16: Time-Based Analysis - Calculate the 30-day rolling average order amount per customer\n",
    "# Expected Output: DataFrame with [customer_id, order_date, total_amount, rolling_avg_30d]\n",
    "# Should show the average order amount for each customer over their preceding 30-day window\n",
    "rolling_avg = (\n",
    "    orders_df\n",
    "    .withColumn('rolling_avg_30d', \n",
    "                avg('total_amount')\n",
    "                .over(\n",
    "                    Window\n",
    "                    .partitionBy('customer_id')\n",
    "                    .orderBy(col('order_date').cast('timestamp').cast('long'))\n",
    "                    .rangeBetween(-30 * 86400, 0)\n",
    "                )\n",
    "    )\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'order_date',\n",
    "        'total_amount',\n",
    "        'rolling_avg_30d'\n",
    "    )\n",
    ")\n",
    "\n",
    "rolling_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======>          (4 + 6) / 10][Stage 16:===========>     (7 + 3) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------+---------------------+\n",
      "|customer_id|   name|last_order_date|days_since_last_order|\n",
      "+-----------+-------+---------------+---------------------+\n",
      "|          1|  Alice|     2023-02-05|                  784|\n",
      "|          2|    Bob|     2023-03-15|                  746|\n",
      "|          3|Charlie|     2023-02-18|                  771|\n",
      "|          4|  David|     2023-03-01|                  760|\n",
      "+-----------+-------+---------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Problem 17: Customer Churn Prediction - Identify customers at risk of churning \n",
    "# (No orders for ≥60 days from their last order date)\n",
    "# Expected Output: DataFrame with [customer_id, name, last_order_date, days_since_last_order]\n",
    "# Should only include customers with ≥1 order who meet the 60-day threshold\n",
    "\n",
    "potential_churn = (\n",
    "    orders_df\n",
    "    .groupBy('customer_id')\n",
    "    .agg(\n",
    "        max('order_date').alias('last_order_date'),\n",
    "        count('order_id').alias('order_count')\n",
    "    )\n",
    "    .withColumn('days_since_last_order', datediff(current_date(), col('last_order_date')))\n",
    "    .filter(\n",
    "        (col('days_since_last_order') >= 60) &\n",
    "        (col('order_count') >= 1)\n",
    "    )\n",
    "    .join(customers_df, 'customer_id')\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'name',\n",
    "        'last_order_date',\n",
    "        'days_since_last_order'\n",
    "    )\n",
    ")\n",
    "\n",
    "potential_churn.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+-------------+----------+\n",
      "|product1_id|product1_name|product2_id|product2_name|pair_count|\n",
      "+-----------+-------------+-----------+-------------+----------+\n",
      "|       1001|       Laptop|       1002|   Smartphone|         1|\n",
      "|       1001|       Laptop|       1003|   Headphones|         1|\n",
      "+-----------+-------------+-----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 18A: Frequently Bought Together Pairs\n",
    "# Find product pairs that appear together in orders more than twice\n",
    "# \n",
    "# Expected Output: DataFrame with [product1_id, product1_name, product2_id, product2_name, pair_count]\n",
    "\n",
    "frequent_pairs = (\n",
    "    order_items_df.alias('oi1')\n",
    "    .join(order_items_df.alias('oi2'),\n",
    "        (col('oi1.order_id') == col('oi2.order_id')) &\n",
    "        (col('oi1.product_id') < col('oi2.product_id'))\n",
    "    )\n",
    "    .groupBy(col('oi1.product_id'), col('oi2.product_id'))\n",
    "    .agg(count('oi1.order_id').alias('pair_count'))\n",
    "    # .filter(col('pair_count') > 2)\n",
    "    .join(products_df.alias('p1'), col('oi1.product_id') == col('p1.product_id'))\n",
    "    .join(products_df.alias('p2'), col('oi2.product_id') == col('p2.product_id'))\n",
    "    .select(\n",
    "        col('oi1.product_id').alias('product1_id'),\n",
    "        col('p1.name').alias('product1_name'),\n",
    "        col('oi2.product_id').alias('product2_id'),\n",
    "        col('p2.name').alias('product2_name'),\n",
    "        'pair_count'\n",
    "    )\n",
    "    .orderBy(col('pair_count').desc())\n",
    ")\n",
    "\n",
    "frequent_pairs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------------+--------------+\n",
      "|customer_id|   name|favorite_category|purchase_count|\n",
      "+-----------+-------+-----------------+--------------+\n",
      "|          1|  Alice|      Accessories|             2|\n",
      "|          2|    Bob|      Electronics|             1|\n",
      "|          3|Charlie|      Electronics|             2|\n",
      "|          4|  David|      Accessories|             1|\n",
      "+-----------+-------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 19: Customer Product Preferences - For each customer, find their most purchased product category\n",
    "# \n",
    "# Expected Output: DataFrame with [customer_id, name, favorite_category, purchase_count]\n",
    "# \n",
    "# Rules:\n",
    "# 1. Calculate category counts from order_items and products\n",
    "# 2. For ties, select the category with the highest total spending\n",
    "# 3. Include all customers (even those with no orders)\n",
    "# \n",
    "# Example:\n",
    "# Alice: 3 Electronics purchases ($1200 total) vs 2 Accessories ($200) → Electronics\n",
    "\n",
    "preferred_category = (\n",
    "    order_items_df.alias('oi')\n",
    "    .join(products_df.alias('p'), 'product_id')\n",
    "    .join(orders_df.alias('o'), 'order_id')\n",
    "    .join(customers_df.alias('c'), 'customer_id', 'right')\n",
    "    .groupBy('customer_id', col('c.name'), 'category')\n",
    "    .agg(\n",
    "        count('order_id').alias('purchase_count'),\n",
    "        sum('total_amount').alias('total_spend')\n",
    "    )\n",
    "    .withColumn('rank', \n",
    "                rank()\n",
    "                .over(\n",
    "                    Window\n",
    "                    .partitionBy('customer_id')\n",
    "                    .orderBy(\n",
    "                        col('purchase_count').desc(),\n",
    "                        col('total_spend').desc()\n",
    "                    )\n",
    "                )\n",
    "    )\n",
    "    .filter(col('rank') == 1)\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'name',\n",
    "        col('category').alias('favorite_category'),\n",
    "        'purchase_count'\n",
    "    )\n",
    ")\n",
    "\n",
    "preferred_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/30 11:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+-----------+------------+\n",
      "|customer_id|   name|total_spend|order_count|  value_tier|\n",
      "+-----------+-------+-----------+-----------+------------+\n",
      "|          2|    Bob|      320.0|          2|  High Value|\n",
      "|          1|  Alice|     225.75|          2|  Occasional|\n",
      "|          3|Charlie|     300.75|          1|Low Activity|\n",
      "|          4|  David|       50.0|          1|Low Activity|\n",
      "+-----------+-------+-----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 20: Customer Value Segmentation - Classify customers into value tiers based on both spending and order frequency\n",
    "# \n",
    "# Expected Output: DataFrame with [customer_id, name, total_spend, order_count, value_tier]\n",
    "# \n",
    "# Segmentation Rules:\n",
    "# ⭐ High Value: Top 20% by spend AND top 20% by order count  \n",
    "# 💎 Consistent: Not high-value but top 50% in both metrics  \n",
    "# 🛒 Occasional: Bottom 50% in spend but top 50% in frequency  \n",
    "# 💸 Big Spenders: Top 20% in spend but bottom 50% in frequency  \n",
    "# 🐌 Low Activity: Bottom 50% in both metrics\n",
    "# \n",
    "# Requirements:\n",
    "# 1. Use percent_rank() for percentile calculations\n",
    "# 2. Handle ties at threshold boundaries\n",
    "# 3. Include all customers (even those with no orders)\n",
    "# \n",
    "# Example:\n",
    "# Alice: total_spend=$1200 (85th %ile), order_count=5 (90th %ile) → ⭐ High Value\n",
    "\n",
    "customer_value_segmentation = (\n",
    "    customers_df\n",
    "    .join(orders_df, 'customer_id', 'left')\n",
    "    .groupBy('customer_id', 'name')\n",
    "    .agg(\n",
    "        coalesce(sum('total_amount'), lit(0)).alias('total_spend'),\n",
    "        coalesce(countDistinct('order_id'), lit(0)).alias('order_count')\n",
    "    )\n",
    "    .withColumn(\n",
    "        'total_spend_pct_rank',\n",
    "        percent_rank()\n",
    "        .over(\n",
    "            Window\n",
    "            .orderBy(col('total_spend').desc())\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        'order_count_pct_rank',\n",
    "        percent_rank()\n",
    "        .over(\n",
    "            Window\n",
    "            .orderBy(col('order_count').desc())\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        'value_tier',\n",
    "        when((col('total_spend_pct_rank') <= 0.2) & (col('order_count_pct_rank') <= 0.2), 'High Value')\n",
    "        .when(\n",
    "            ((col('total_spend_pct_rank') <= 0.5) & (col('order_count_pct_rank') <= 0.5)) & \n",
    "            ~((col('total_spend_pct_rank') <= 0.2) & (col('order_count_pct_rank') <= 0.2)), 'Consistent')\n",
    "        .when((col('total_spend_pct_rank') > 0.5) & (col('order_count_pct_rank') <= 0.5), 'Occasional')\n",
    "        .when((col('total_spend_pct_rank') <= 0.2) & (col('order_count_pct_rank') > 0.5), 'Big Spenders')\n",
    "        .otherwise('Low Activity')\n",
    "    )\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'name',\n",
    "        'total_spend',\n",
    "        'order_count',\n",
    "        'value_tier'\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "customer_value_segmentation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datachat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
